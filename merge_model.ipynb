{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82611524",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unsloth\n",
    "# Also get the latest nightly Unsloth!\n",
    "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git@nightly git+https://github.com/unslothai/unsloth-zoo.git\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "from peft import PeftModel\n",
    "from huggingface_hub import login, HfApi, create_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82154d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.11.6: Fast Qwen2 patching. Transformers: 4.57.2.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f3e1552c0f457797722940a465d875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb16492abda4d318d5c106b799ab65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02809bee24ab4be3a923e5a824ed43a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe7d0a2e2364a798b8c47eca987f95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1019e5127a42dd8dede31451552552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e6635837084e13ac49457e94fd05fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/107 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e44333976f748d3bf150fb5a6b4bf53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/256 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c8b4a9ddc048e491a1c7c65f15d211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TOKEN = None\n",
    "ORG_PATH = \"StefanCoder1/Granite-tuned\" \n",
    "NEW_PATH = \"StefanCoder1/Qwen-tunded\"\n",
    "\n",
    "def load_new(path = ORG_PATH):\n",
    "    max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "    dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "    load_in_4bit = False\n",
    "\n",
    "    org_model, org_tokenizer = FastLanguageModel.from_pretrained(\n",
    "          model_name = \"unsloth/Qwen2-0.5B-bnb-4bit\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "          max_seq_length = max_seq_length,\n",
    "          dtype = dtype,\n",
    "          load_in_4bit = load_in_4bit,\n",
    "          # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    "      )\n",
    "\n",
    "    model = PeftModel.from_pretrained(\n",
    "    org_model,\n",
    "    path, \n",
    "    token=TOKEN,\n",
    "    )\n",
    "    merged = model.merge_and_unload()\n",
    "\n",
    "    return merged, org_tokenizer\n",
    "\n",
    "def create_HF_repo(repo_name, token=TOKEN):\n",
    "    login(token=TOKEN) # dont steal it please :((((\n",
    "    api = HfApi()\n",
    "    user = api.whoami()[\"name\"]\n",
    "    repo_id = f\"{repo_name}\"\n",
    "    # Ensure repo exists\n",
    "    create_repo(repo_id, private=True, exist_ok=True)\n",
    "    return repo_id\n",
    "\n",
    "repo_id =create_HF_repo(NEW_PATH)\n",
    "model, tokenizer = load_new(ORG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6399fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
    "model.push_to_hub(NEW_PATH, tokenizer, token =TOKEN)\n",
    "tokenizer.push_to_hub(NEW_PATH,use_auth_token=TOKEN, \n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
